# 配置文件，用于联合微调阶段的训练，包括数据集、模型和训练参数。

dataset:
  name: COCO # 或 PASCAL_VOC 等
  # 假设已使用 prepare_detection_data.py 生成 LR/ 和 annotations.json 的父目录
  image_dir: "dataset/date_prepared" 
  annotation_file: "dataset/date_prepared/annotations.json" 
  scale_factor: 4 # 必须与 SR 模型匹配

# Model Configuration
model:
  # ConditionalSR 子模块参数 (应与 stage2 匹配)
  sr_fast:
    in_channels: 3
    d: 56
    s: 12
    m: 4
    scale_factor: 4
  sr_quality:
    in_channels: 3
    num_channels: 64
    num_blocks: 16
    scale_factor: 4
  masker:
    in_channels: 3
    base_channels: 32
    num_blocks: 4
    output_channels: 1 # 输出单通道 logits
    output_patch_size: 16 # Masker 输出相对于 LR 输入的下采样因子 (粗粒度)
    threshold: 0.5 # 推理时硬掩码的阈值

  # 预训练权重路径
  weights:
    sr_fast: "./temp_checkpoints/stage2_sr/sr_fast_pretrained.pth"
    sr_quality: "./temp_checkpoints/stage2_sr/sr_quality_pretrained.pth"
    masker: null # 如果有预训练 Masker 权重，提供路径
    detector: "./temp_checkpoints/stage1_yolo/yolo_pretrained_hr.pt" # YOLOv8 .pt 权重

  # YOLO 模型特定参数
  num_classes: 2 # 数据集中的类别数量 (例如: block, bolt -> 2)
  yolo_params:
    reg_max: 16   
    strides: [8.0, 16.0, 32.0] 

# Training Configuration
train:
  epochs: 100 # <--- 修改: 大幅增加训练轮数, 例如 100-150 轮，根据收敛情况调整
  batch_size: 8 # <--- 修改: RTX 3090 可以尝试更大的批次大小, 例如 8, 16。如果OOM则减小。

  # 差分学习率配置 (初始值可以保留，后续根据训练情况调整)
  learning_rates:
    high_lr: 0.0001 
    low_lr: 0.000001 

  # 优化器
  optimizer:
    name: AdamW
    args:
      weight_decay: 0.0005

  # 学习率调度器
  scheduler:
    name: CosineAnnealingLR
    args:
      # T_max 将在脚本中根据 epochs 和 dataloader 长度动态计算 (如果脚本支持)
      # 如果脚本不支持动态计算，你需要手动设置 T_max = total_epochs * (num_train_images / batch_size)
      # 假设 num_train_images = 1252, batch_size = 8, epochs = 100
      # steps_per_epoch = 1252 / 8 = 157 (向上取整)
      # T_max = 100 * 157 = 15700
      T_max: 15700 # <--- 修改: 配合新的 epochs 和 batch_size (示例值)
      eta_min: 0.0000001

  # 联合损失函数权重 (初始值可以保留，后续根据训练情况调整)
  loss_weights:
    detection: 1.0 
    sparsity: 0.05  # <--- 可选修改: 稍微降低稀疏度损失权重，让模型初期更关注检测本身
    smoothness: 0.01 

  # YOLO 特定损失的超参数
  yolo_hyp:
    box: 7.5  
    cls: 0.5  
    dfl: 1.5  
    label_smoothing: 0.0 

  # TaskAlignedAssigner 参数
  yolo_assigner_params:
    topk: 10
    alpha: 0.5 
    beta: 6.0  
    use_ciou_for_tal_metric: False 

  # 稀疏度目标
  target_sparsity_ratio: 0.2 

  # Gumbel-Softmax 温度
  gumbel:
    initial_tau: 2.0
    final_tau: 0.5
    # anneal_epochs 和 anneal_steps 的关系:
    # 如果 anneal_steps 设置为 null 或无效值, 则 anneal_steps = anneal_epochs * steps_per_epoch
    # 为了在新的总训练轮数内有效退火:
    anneal_epochs: 80 # <--- 修改: 例如，在总轮数的 80% 完成退火
    anneal_steps: null 
    anneal_schedule: "cosine" 

  device: "cpu" # 会被命令行 --use_gpu 覆盖为 "cuda"
  num_workers: 8 # <--- 修改: 根据你的CPU核心数调整, 例如 4, 8, 16。对于64GB内存，8-16个worker应该可以
  seed: 42
  log_interval_steps: 50 # <--- 修改: 可以适当增加记录间隔，比如每50或100步

# Logging and Saving
log_dir: "./temp_logs/stage3_joint"
checkpoint_dir: "./temp_checkpoints/stage3_joint"
# save_interval 和 eval_interval 由命令行参数控制

# Evaluation
evaluation:
  metric: "map" 
  val_image_dir: "dataset/date_prepared" 
  val_annotation_file: "dataset/date_prepared/annotations.json"